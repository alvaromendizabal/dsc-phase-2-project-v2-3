{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "import folium\n",
    "KC_coord = (47.4081,-121.9949)\n",
    "Seattle_coord = (47.6062,-122.3321)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-notebook')\n",
    "#from yellowbrick.regressor import ResidualsPlot\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.api import OLS\n",
    "\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, OrdinalEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/kc_house_data.csv', index_col=0, parse_dates=['date']) \n",
    "# specify index_col=0 to avoid creating an \"Unnamed: 0\" column.\n",
    "# specify parse date to avoid object dtype for dates\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(df.corr());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterfront_count = df['waterfront'].value_counts()\n",
    "waterfront_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterfront_proportions = df['waterfront'].value_counts()[1] / df['waterfront'].value_counts()[0]\n",
    "waterfront_proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "watefront_null_proportion = df['waterfront'].isna().sum() * waterfront_proportions\n",
    "watefront_null_proportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterfront_yes = df.loc[ df['waterfront'] == 'YES' ]\n",
    "\n",
    "waterfront_avg_yes_price = np.mean( waterfront_yes['price'] )\n",
    "waterfront_med_yes_price = np.median( waterfront_yes['price'] )\n",
    "\n",
    "waterfront_null = df[df['waterfront'].isna()]\n",
    "waterfront_null.loc[~waterfront_null.index.duplicated(), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterfront_null_avg_filter = waterfront_null.loc[ waterfront_null['price'] >= waterfront_avg_yes_price ]\n",
    "waterfront_null_med_filter = waterfront_null.loc[ waterfront_null['price'] >= waterfront_med_yes_price ]\n",
    "waterfront_med = np.median(waterfront_null_med_filter['price'])\n",
    "\n",
    "\n",
    "waterfront_null_avg_count = len(waterfront_null_avg_filter)  \n",
    "waterfront_null_med_count = len(waterfront_null_med_filter) \n",
    "\n",
    "waterfront_convert = waterfront_null_med_count * waterfront_proportions\n",
    "\n",
    "print(f\"\"\"mean: {np.round(waterfront_avg_yes_price, 2)}, count: {waterfront_null_avg_count} \n",
    "\n",
    "median: {waterfront_med_yes_price}, count: {waterfront_null_med_count}\n",
    "\n",
    "waterfront_convert: {waterfront_convert}\n",
    "\n",
    "median waterfront homes >= waterfront_med_yes_price: {waterfront_med}\n",
    "\n",
    "{waterfront_null_med_filter}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_count = df['view'].value_counts()\n",
    "view_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_count = df['condition'].value_counts()\n",
    "condition_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedroom_count = df['bedrooms'].value_counts()\n",
    "bedroom_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the 33 bedroom outlier \n",
    "df = df[df['bedrooms'] != 33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bedrooms_bin']=pd.cut(df['bedrooms'], bins = [0,1,2,3,4,5,6,99], labels=['1 bed','2 bed','3 bed','4 bed','5 bed','6 bed','7+ bed'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the 33 bedroom outlier \n",
    "df.drop(['date', 'yr_renovated', 'sqft_basement'], axis=1, inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taking Out Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Price Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate 25, 75, iqr, whiskers for 'price'\n",
    "price_q25, price_q75 = np.percentile(df['price'], [25, 75])\n",
    "price_iqr = price_q75 - price_q25\n",
    "price_min = price_q25 - (1.5 * price_iqr)\n",
    "price_max = price_q75 + (1.5 * price_iqr)\n",
    "\n",
    "print(f\"\"\"price_min: {price_min} \n",
    "price_max: {price_max}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set df to include everything within the whiskers except the outliers\n",
    "df = df[df['price'] >= price_min]\n",
    "df = df[df['price'] <= price_max]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sqft Lot Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate 25, 75, iqr, whiskers for 'sqft_lot'\n",
    "sqft_lot_q25, sqft_lot_q75 = np.percentile(df['sqft_lot'], [25, 75])\n",
    "sqft_lot_iqr = sqft_lot_q75 - sqft_lot_q25\n",
    "sqft_lot_min = sqft_lot_q25 - (1.5 * sqft_lot_iqr)\n",
    "sqft_lot_max = sqft_lot_q75 + (1.5 * sqft_lot_iqr)\n",
    "\n",
    "\n",
    "print(f\"\"\"sqft_lot_min: {sqft_lot_min} \n",
    "sqft_lot_max: {sqft_lot_max}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set df to include everything within the whiskers except the outliers\n",
    "df = df[df['sqft_lot'] >= sqft_lot_min]\n",
    "df = df[df['sqft_lot'] <= sqft_lot_max]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grade Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check value counts of grades\n",
    "grade_count = print(df['grade'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['grade'] != '3 Poor']\n",
    "df = df[df['grade'] != '12 Luxury']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ohe executes 2 transformations, test and train. data for any given input variable: First, we use OneHotEncoder to split up our categorical variables. Second, we run a linear regression on encoded values using .fit(). Then, it takes in a training df ('df'), a test df ('df2') and a column name. Next, it returns the training df and the test df concatenated with newly encoded columns. Lastly, we return a list of these newly encoded column names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohe(df, df2, column):\n",
    "    for col in column:\n",
    "        train = df[[col]]\n",
    "        ohe = OneHotEncoder(drop='first', sparse=False, handle_unknown=\"error\")\n",
    "        ohe.fit(train)\n",
    "        encoded_train = ohe.transform(train)\n",
    "        col_labels = [f\"{col}_{f}\" for f in ohe.get_feature_names()]\n",
    "        encoded_train = pd.DataFrame(encoded_train, columns=col_labels, index=df.index)\n",
    "        df = pd.concat([df, encoded_train], axis=1)\n",
    "        \n",
    "        test = df2[[col]]\n",
    "        encoded_test = ohe.transform(test)\n",
    "        col_labels = [f\"{col}_{f}\" for f in ohe.get_feature_names()]\n",
    "        encoded_test = pd.DataFrame(encoded_test, columns=col_labels, index=df2.index)\n",
    "        df2 = pd.concat([df2, encoded_test], axis=1)\n",
    "        \n",
    "    return df, df2, encoded_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run a Standard Scaler to scale all the values in the test data and training data so that our models results are in comparable units. Then, we score the scaled data to get the R2 to assess the strength of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_score(x, y, x2, y2):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x)\n",
    "    X_train_scaled = scaler.transform(x)\n",
    "    X_test_scaled = scaler.transform(x2)\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    train_pred = model.predict(X_train_scaled)\n",
    "    test_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    print(f\"\"\"training score: {r2_score(y_train, train_pred)}\n",
    "    test score: {r2_score(y_test, test_pred)}\"\"\")\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, train_pred, test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses price and predictions to calculate Mean Absolute Error (MAE), Mean Squared Error (MSE) and Root Mean Squared Error (RSME) for the training and testing data sets. We will compare these values to evaluate model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_metrics(y_train,train_preds,\n",
    "               y_test,test_preds\n",
    "              ):\n",
    "    \"\"\"\n",
    "    Prints different training and testing metrics, namely R2, MAE, MSE, RMSE\n",
    "    \"\"\"\n",
    "    print(\"\\nTraining Metrics:\")\n",
    "    print(f\"R2: {r2_score(y_train, train_preds):.3f}\")\n",
    "    print(f\"Mean Absolute Error: {mean_absolute_error(y_train, train_preds):.3f}\")\n",
    "    print(f\"Mean Squared Error: {mean_squared_error(y_train, train_preds):.3f}\")\n",
    "    print(f\"Root Mean Squared Error: {mean_squared_error(y_train, train_preds, squared=False):.3f}\")\n",
    "    \n",
    "    print(\"\\nTesting Metrics:\")\n",
    "    print(f\"R2: {r2_score(y_test, test_preds):.3f}\")\n",
    "    print(f\"Mean Absolute Error: {mean_absolute_error(y_test, test_preds):.3f}\")\n",
    "    print(f\"Mean Squared Error: {mean_squared_error(y_test, test_preds):.3f}\")\n",
    "    print(f\"Root Mean Squared Error: {mean_squared_error(y_test, test_preds, squared=False):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['price']\n",
    "X = df.drop('price', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, encoded_condition = ohe(X_train, X_test, ['condition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['condition'] = X_train['condition'].map({'Very Good': 5, 'Good': 4, 'Average': 3, 'Fair': 2, 'Poor': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['condition'] = X_test['condition'].map({'Very Good': 5, 'Good': 4, 'Average': 3, 'Fair': 2, 'Poor': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['view'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['view'].fillna('NONE', inplace=True)\n",
    "X_test['view'].fillna('NONE', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train, X_test, encoded_view = ohe(X_train, X_test, ['view'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['view'] = X_train['view'].map({'EXCELLENT': 5, 'GOOD': 4, 'AVERAGE': 3, 'FAIR': 2, 'NONE': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['view'] = X_test['view'].map({'EXCELLENT': 5, 'GOOD': 4, 'AVERAGE': 3, 'FAIR': 2, 'NONE': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Waterfront"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['waterfront'].fillna('NO', inplace=True)\n",
    "X_test['waterfront'].fillna('NO', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterfront_train = X_train[['waterfront']]\n",
    "\n",
    "encoder_waterfront = OrdinalEncoder()\n",
    "encoder_waterfront.fit(waterfront_train)\n",
    "encoder_waterfront.categories_[0]\n",
    "waterfront_encoded_train = encoder_waterfront.transform(waterfront_train)\n",
    "waterfront_encoded_train = waterfront_encoded_train.flatten()\n",
    "\n",
    "X_train['waterfront'] = waterfront_encoded_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterfront_test = X_test[['waterfront']]\n",
    "\n",
    "encoder_waterfront = OrdinalEncoder()\n",
    "encoder_waterfront.fit(waterfront_test)\n",
    "encoder_waterfront.categories_[0]\n",
    "waterfront_encoded_test = encoder_waterfront.transform(waterfront_test)\n",
    "waterfront_encoded_test = waterfront_encoded_train.flatten()\n",
    "\n",
    "X_train['waterfront'] = waterfront_encoded_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bedroom Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, encoded_bedrooms_bins = ohe(X_train, X_test, ['bedrooms_bin'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, encoded_grade = ohe(X_train, X_test, ['grade'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, encoded_zipcode = ohe(X_train, X_test, ['zipcode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy = DummyRegressor()\n",
    "dummy.fit(X_train, y_train)\n",
    "dummy.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['sqft_living']\n",
    "y = y_train\n",
    "x = X_train.filter(cols, axis=1)\n",
    "y2 = y_test\n",
    "x2 = X_test.filter(cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_test_scaled, train_preds, test_preds = scale_score(x, y, x2, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_sqft_liv = df['price']\n",
    "X_sqft_liv = df['sqft_living']\n",
    "\n",
    "model = sm.OLS(y_sqft_liv, sm.add_constant(X_sqft_liv)).fit()\n",
    "model_summary = model.summary()\n",
    "model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()['price'].abs().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/kc_house_data.csv', index_col=0, parse_dates=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a heatmap to see correlations\n",
    "plt.figure(figsize=(12, 6))\n",
    "mask = np.triu(np.ones_like(df.corr(), dtype=bool))\n",
    "heatmap = sns.heatmap(df.corr(), mask=mask, vmin=-1, vmax=1, annot=True)\n",
    "heatmap.set_title('Triangle Correlation Heatmap', fontdict={'fontsize':18}, pad=16);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "highcor = ['bathrooms', 'sqft_above','sqft_living15','sqft_lot15','grade']\n",
    "relcols = ['price', 'bedrooms', 'bathrooms', 'sqft_living', 'floors', 'sqft_above', 'sqft_living15']\n",
    "sns.pairplot(df, corner=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Created a functions to get models, summaries, and encode data\n",
    "def getmodel(X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    mod = LinearRegression()\n",
    "    mod.fit(X_train, y_train)\n",
    "    pred = mod.predict(X_test)\n",
    " \n",
    "    print(f'y intercept: {mod.intercept_}')\n",
    "    print(f'slope: {mod.coef_}')\n",
    "    print(f'R2: %.3f' %r2_score(y_test, pred))\n",
    "    print(f'mean2 error: %.3f' %mean_squared_error(y_test, pred))\n",
    "    print(f'predicted path: {pred}')\n",
    "    \n",
    "    Xrline = mod.coef_*X_test+mod.intercept_\n",
    "    plt.scatter(y_test, pred, alpha=0.25);\n",
    "    plt.plot(pred, Xrline);\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def getols(x,y):\n",
    "    \n",
    "    x = sm.add_constant(x)\n",
    "    result = sm.OLS(y, x).fit()\n",
    "    print(result.summary())\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "def odinalencode(x):\n",
    "    encode_x = OrdinalEncoder()\n",
    "\n",
    "    encode_x.fit(x)\n",
    "\n",
    "    x_encoded = encode_x.transform(x)\n",
    "    x_encoded = x_encoded.flatten()\n",
    "    return x_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['waterfront'] = df['waterfront'].replace(np.nan, 'NO')\n",
    "df['waterfront'] = odinalencode(df[['waterfront']])\n",
    "\n",
    "viewdict = {'NONE':1,'AVERAGE':2,'GOOD':3,'FAIR':4,'EXCELLENT':5}\n",
    "df['view'] = df['view'].map(viewdict)\n",
    "\n",
    "condict = {'Poor':1,'Fair':2,'Fair':3,'Average':4,'Good':5,'Very Good':6}\n",
    "df['condition'] = df['condition'].map(condict)\n",
    "\n",
    "gradedict = {'3 Poor':1,'4 Low':2,'5 Fair':3,'6 Low Average':4,'7 Average':7,'8 Good':8,'9 Better':9,'10 Very Good':10,'11 Excellent':11,'12 Luxury':12,'13 Mansion':13}\n",
    "df['grade'] = df['grade'].map(gradedict)\n",
    "\n",
    "df['sqft_basement'] = df['sqft_basement'].map({'?':0})\n",
    "df['sqft_basement'] = df['sqft_basement'].replace(np.nan, 0)\n",
    "\n",
    "df['yr_renovated'] = df['yr_renovated'].replace(np.nan, 0)\n",
    "\n",
    "df.drop('view',axis=1,inplace=True)\n",
    "df.drop('date',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bathModel = getmodel(df[['price']], df['bathrooms'])\n",
    "bathols = getols(df[['price']], df['bathrooms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqft_liv = getmodel(df[['price']], df['sqft_living'])        \n",
    "sqft_livols = getols(df[['price']], df['sqft_living'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sqft15 = getmodel(df[['price']], df['sqft_living15'])\n",
    "sqftols = getols(df[['price']], df['sqft_living15'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = df.drop(['price'],axis=1).values\n",
    "y = df['price'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=0)\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train,y_train)\n",
    "\n",
    "pred = reg.predict(X_test)\n",
    "\n",
    "print(f'r2 score: {r2_score(y_test, pred)}')\n",
    "\n",
    "plt.scatter(y_test,pred,alpha=0.25);\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = df.copy()\n",
    "#Dropping columns for colinearity\n",
    "newdf.drop(highcor, axis=1, inplace=True)\n",
    "newdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X = newdf.drop(['price'],axis=1).values\n",
    "y = newdf['price'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=0)\n",
    "\n",
    "reg.fit(X_train,y_train)\n",
    "\n",
    "pred = reg.predict(X_test)\n",
    "\n",
    "print(f'r2 score: {r2_score(y_test, pred)}')\n",
    "#getols(y_test,pred)\n",
    "plt.scatter(y_test,pred,alpha=0.25);\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a fuction to find mean price per zipcode\n",
    "def zipmean(x):\n",
    "    y = df[df['zipcode'] == x]\n",
    "    m = int(y[\"price\"].mean())\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['zipcode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipmean(98103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a list for unique zipcodes and for their average home value\n",
    "ziplist = []\n",
    "zipprice = []\n",
    "for i in df['zipcode']:\n",
    "    b = zipmean(i)\n",
    "    if b in zipprice:\n",
    "        continue\n",
    "    else:\n",
    "        zipprice.append(b)\n",
    "    if i in ziplist:\n",
    "        continue\n",
    "    else:\n",
    "        ziplist.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing results to make sure they equal in length\n",
    "print(len(ziplist))\n",
    "print(len(zipprice))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating list of zipcode price mean values from original dataframe\n",
    "avg_zip_price = []\n",
    "for i in df['zipcode']:\n",
    "    m = zipmean(i)\n",
    "    avg_zip_price.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating column for average home price per zipcode\n",
    "df['avg_zip_price'] = avg_zip_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ranking zipcodes based on their average home prices\n",
    "zip_rank = []\n",
    "for i in df['avg_zip_price']:\n",
    "    if i >= 1600000:\n",
    "        zip_rank.append(1)\n",
    "    elif i >= 1200000:\n",
    "        zip_rank.append(2)\n",
    "    elif i >= 800000:\n",
    "        zip_rank.append(3)  \n",
    "    elif i >= 400000:\n",
    "        zip_rank.append(4) \n",
    "    else:\n",
    "        zip_rank.append(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Column for zipcode ranks\n",
    "df['zip_rank'] = zip_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Checking column for correct values\n",
    "df['zip_rank'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = newdf.drop(['price'],axis=1).values\n",
    "y = newdf['price'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=0)\n",
    "\n",
    "reg.fit(X_train,y_train)\n",
    "\n",
    "pred = reg.predict(X_test)\n",
    "\n",
    "print(f'r2 score: {r2_score(y_test, pred)}')\n",
    "#getols(y_test,pred)\n",
    "plt.scatter(y_test,pred,alpha=0.25);\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted');\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Creating heatmap style seaborn scatterplot based on average price per location\n",
    "x = df['long']\n",
    "y = df['lat']\n",
    "h = df['avg_zip_price']\n",
    "sns.scatterplot(x,y,hue=h).set(title='Zipcodes by home value');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating seaborn scatterplot for different zipcodes\n",
    "sns.scatterplot(x=df['long'],y=df['lat'],hue=df['zipcode']).set(title='Map by zipcodes');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating heatmap style MPL scatterplot based on average price per location\n",
    "colors = df['zip_rank']\n",
    "\n",
    "lon = df['long']\n",
    "lat = df['lat']\n",
    "plt.scatter(lon,lat,c=colors,alpha=0.5);\n",
    "plt.xlabel('Longitude');\n",
    "plt.ylabel('Latitude');\n",
    "plt.title('MPL plot by zip_avg_price');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#creating MPL scatterplot for different zipcodes\n",
    "colors = df['zipcode']\n",
    "\n",
    "lon = df['long']\n",
    "lat = df['lat']\n",
    "plt.scatter(lon,lat,c=colors,alpha=0.5);\n",
    "plt.title('Map of houses by zipcode')\n",
    "plt.xlabel('Longitude');\n",
    "plt.ylabel('Latitude');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['long']\n",
    "y = df['lat']\n",
    "h = df['sqft_living']\n",
    "sns.scatterplot(x,y,hue=h).set(title='Zipcodes by home sqft_living');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['long']\n",
    "y = df['lat']\n",
    "h = df['grade']\n",
    "sns.scatterplot(x,y,hue=h).set(title='Zipcodes by home grade');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['long']\n",
    "y = df['lat']\n",
    "h = df['price']\n",
    "sns.scatterplot(x,y,hue=h).set(title='Zipcodes by individual home value');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
